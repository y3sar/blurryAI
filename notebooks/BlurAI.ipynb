{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad86d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d48736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import maskrcnn_resnet50_fpn_v2, MaskRCNN_ResNet50_FPN_V2_Weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import draw_segmentation_masks, draw_bounding_boxes\n",
    "import random\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def random_color_gen(n):\n",
    "    return [tuple(random.randint(0,255) for i in range(3)) for i in range(n)]\n",
    "\n",
    "import math\n",
    "\n",
    "def get_gaussian_kernel(kernel_size=15, sigma=20, channels=3):\n",
    "    # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "    x_coord = torch.arange(kernel_size)\n",
    "    x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "    y_grid = x_grid.t()\n",
    "    xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "\n",
    "    mean = (kernel_size - 1)/2.\n",
    "    variance = sigma**2.\n",
    "\n",
    "    # Calculate the 2-dimensional gaussian kernel which is\n",
    "    # the product of two gaussian distributions for two different\n",
    "    # variables (in this case called x and y)\n",
    "    gaussian_kernel = (1./(2.*math.pi*variance)) *\\\n",
    "                      torch.exp(\n",
    "                          -torch.sum((xy_grid - mean)**2., dim=-1) /\\\n",
    "                          (2*variance)\n",
    "                      )\n",
    "\n",
    "    # Make sure sum of values in gaussian kernel equals 1.\n",
    "    gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "\n",
    "    # Reshape to 2d depthwise convolutional weight\n",
    "    gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size, kernel_size)\n",
    "    gaussian_kernel = gaussian_kernel.repeat(channels, 1, 1, 1)\n",
    "\n",
    "    gaussian_filter = nn.Conv2d(in_channels=channels, out_channels=channels,\n",
    "                                kernel_size=kernel_size, padding='same', groups=channels, bias=False)\n",
    "\n",
    "    gaussian_filter.weight.data = gaussian_kernel\n",
    "    gaussian_filter.weight.requires_grad = False\n",
    "    \n",
    "    return gaussian_filter\n",
    "\n",
    "\n",
    "output_dict = {} # this dict is shared between segment and blur_background functions\n",
    "pred_label_unq = []\n",
    "\n",
    "def segment(input_image):\n",
    "    \n",
    "    # prepare image for display\n",
    "    display_img = torch.tensor(np.asarray(input_image)).unsqueeze(0)\n",
    "    display_img =  display_img.permute(0, 3, 1, 2).squeeze(0)\n",
    "    \n",
    "    # Prepare the RCNN model\n",
    "    weights = MaskRCNN_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "    transforms = weights.transforms()\n",
    "    model = maskrcnn_resnet50_fpn_v2(weights=weights)\n",
    "    model = model.eval();\n",
    "    \n",
    "    # Prepare the input image\n",
    "    input_tensor = transforms(input_image).unsqueeze(0)\n",
    "    \n",
    "    # Get the predictions\n",
    "    output = model(input_tensor)[0] # idx 0 to get the first dictionary of the returned list\n",
    "    \n",
    "    \n",
    "    # Filter by threshold\n",
    "    score_threshold = 0.75\n",
    "    mask_threshold = 0.5\n",
    "    masks = output['masks'][output['scores'] > score_threshold] > mask_threshold;\n",
    "    boxes = output['boxes'][output['scores'] > score_threshold]\n",
    "    masks = masks.squeeze(1)\n",
    "    boxes = boxes.squeeze(1)\n",
    "    \n",
    "    pred_labels = [weights.meta[\"categories\"][label] for label in output['labels'][output['scores'] > score_threshold]]\n",
    "    n_pred = len(pred_labels)\n",
    "    \n",
    "    # give unique id to all the predicitons\n",
    "    pred_label_unq = [pred_labels[i] + str(pred_labels[:i].count(pred_labels[i]) + 1) for i in range(n_pred)]\n",
    "    \n",
    "    colors = random_color_gen(n_pred)\n",
    "    \n",
    "    # Prepare output_dict\n",
    "    for i in range(n_pred):\n",
    "        output_dict[pred_label_unq[i]] = {'mask': masks[i].tolist(), 'color': colors[i]}\n",
    "        \n",
    "    \n",
    "    masked_img = draw_segmentation_masks(display_img, masks, alpha=0.9, colors=colors)\n",
    "    bounding_box_img = draw_bounding_boxes(masked_img, boxes, labels=pred_label_unq, colors='white')\n",
    "    masked_img = T.ToPILImage()(masked_img)\n",
    "    bounding_box_img = T.ToPILImage()(bounding_box_img)\n",
    "    \n",
    "    return bounding_box_img;\n",
    "\n",
    "def blur_background(input_image, label_name):\n",
    "    mask = output_dict[label_name]['mask']\n",
    "    mask = torch.tensor(mask).unsqueeze(0)\n",
    "    \n",
    "    input_tensor = T.ToTensor()(input_image).unsqueeze(0)\n",
    "    blur = get_gaussian_kernel()\n",
    "    blurred_tensor = blur(input_tensor)\n",
    "    \n",
    "    final_img = blurred_tensor\n",
    "    final_img[:, :, mask.squeeze(0)] = input_tensor[:, :, mask.squeeze(0)];\n",
    "    \n",
    "    final_img = T.ToPILImage()(final_img.squeeze(0))\n",
    "    \n",
    "    return final_img;\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "with gr.Blocks() as app:\n",
    "    \n",
    "    gr.Markdown(\"# Blur an objects background with AI\")\n",
    "    \n",
    "    gr.Markdown(\"First segment the image and create bounding boxes\")\n",
    "    with gr.Column():\n",
    "        input_image = gr.Image(type='pil')\n",
    "        b1 = gr.Button(\"Segment Image\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    with gr.Row():\n",
    "#         masked_image = gr.Image();\n",
    "        bounding_box_image = gr.Image();\n",
    "    \n",
    "    \n",
    "    gr.Markdown(\"Now choose a label (eg: person1) from the above image of your desired object and input it below\")\n",
    "    with gr.Column():\n",
    "        label_name = gr.Textbox()\n",
    "        b2 = gr.Button(\"Blur Backbround\")\n",
    "        result = gr.Image()\n",
    "    \n",
    "    b1.click(segment, inputs=input_image, outputs=bounding_box_image)\n",
    "    b2.click(blur_background, inputs=[input_image, label_name], outputs=result)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     instance_segmentation = gr.Interface(segment, inputs=input_image, outputs=['json', 'image'])\n",
    "\n",
    "app.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7700c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
